{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pima Indians Diabetes Database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pd.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(dataframe):\n",
    "    \"\"\"\n",
    "    Split the dataset into training & test sets using a 70/30 split.\n",
    "    I expect the input dataset to have the class label as the first column\n",
    "    and the feature values as the remaining columns.\n",
    "    \"\"\"\n",
    "\n",
    "    X = array[:,0:8]\n",
    "    Y = array[:,8]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=100)\n",
    "\n",
    "    # Print the shapes of the resulting train and test sets\n",
    "    print(f\"Training features shape: {X_train.shape}, labels shape: {y_train.shape}\")\n",
    "    print(f\"Test features shape: {X_test.shape}, labels shape: {y_test.shape}\")\n",
    "\n",
    "    return X, Y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (537, 8), labels shape: (537,)\n",
      "Test features shape: (231, 8), labels shape: (231,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X, Y, X_train, X_test, y_train, y_test = split_dataframe(dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.25246861 0.29965553 0.2195045  0.21024473 0.40474136 0.29847004]\n",
      "Cross-Predicted Accuracy: 0.2851287142303135\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit a model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(model, X, Y, cv=6)\n",
    "print(\"Cross-validated scores:\", scores)\n",
    "\n",
    "# Make cross validated predictions\n",
    "predictions = cross_val_predict(model, X, Y, cv=6)\n",
    "plt.scatter(Y, predictions)\n",
    "\n",
    "accuracy = metrics.r2_score(Y, predictions)\n",
    "print(\"Cross-Predicted Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a decision tree classifier using the Gini Index\n",
    "def train_decision_tree_gini(X_train, X_test, y_train): \n",
    "    # Create the decision tree classifier object with Gini Index as criterion\n",
    "    clf_gini = DecisionTreeClassifier(criterion=\"gini\", \n",
    "                                       random_state=100,\n",
    "                                       max_depth=3,\n",
    "                                       min_samples_leaf=5) \n",
    "  \n",
    "    # Train the classifier on the training data\n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train decision tree using entropy criterion\n",
    "def train_using_entropy(X_train, X_test, y_train):\n",
    "    \"\"\"\n",
    "    Trains a decision tree classifier using entropy as the split criterion\n",
    "    \n",
    "    Args:\n",
    "    - X_train (array-like, shape = [n_samples, n_features]): Training input samples\n",
    "    - X_test (array-like, shape = [n_samples, n_features]): Test input samples\n",
    "    - y_train (array-like, shape = [n_samples]): Target values for the training set\n",
    "    \n",
    "    Returns:\n",
    "    - clf_entropy (DecisionTreeClassifier): Fitted decision tree classifier using entropy as the split criterion\n",
    "    \"\"\"\n",
    "  \n",
    "    # Create decision tree classifier object\n",
    "    clf_entropy = DecisionTreeClassifier( \n",
    "            criterion = \"entropy\", \n",
    "            random_state = 100, \n",
    "            max_depth = 3, \n",
    "            min_samples_leaf = 5) \n",
    "  \n",
    "    # Fit decision tree classifier to training data\n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    \n",
    "    # Return the trained classifier\n",
    "    return clf_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions using a trained classifier\n",
    "def make_predictions(X_test, clf): \n",
    "\n",
    "    # Predictions using the classifier \n",
    "    y_pred = clf.predict(X_test) \n",
    "    # Print the predicted values (optional)\n",
    "    # print(\"Predicted values:\") \n",
    "    # print(y_pred) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Calculates and prints the accuracy, confusion matrix and classification report \n",
    "    for a set of true labels and predicted labels.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (array-like): The true labels of the data.\n",
    "    y_pred (array-like): The predicted labels for the data.\n",
    "    \"\"\"\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Compute the accuracy score\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy: {:.2f}%\".format(acc*100))\n",
    "\n",
    "    # Compute and print the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Phase \n",
    "clf_gini = train_decision_tree_gini(X_train, X_test, y_train) \n",
    "clf_entropy = train_using_entropy(X_train, X_test, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[140  10]\n",
      " [ 54  27]]\n",
      "Accuracy: 72.29%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.93      0.81       150\n",
      "         1.0       0.73      0.33      0.46        81\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.73      0.63      0.64       231\n",
      "weighted avg       0.72      0.72      0.69       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Make predictions using the gini model\n",
    "y_pred_gini = make_predictions(X_test, clf_gini)\n",
    "\n",
    "# Calculate accuracy of the gini model\n",
    "calculate_accuracy(y_test, y_pred_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[140  10]\n",
      " [ 54  27]]\n",
      "Accuracy: 72.29%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.93      0.81       150\n",
      "         1.0       0.73      0.33      0.46        81\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.73      0.63      0.64       231\n",
      "weighted avg       0.72      0.72      0.69       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict using the entropy classifier\n",
    "y_pred_entropy = make_predictions(X_test, clf_entropy) \n",
    "\n",
    "# Calculate and print the accuracy of the entropy classifier\n",
    "calculate_accuracy(y_test, y_pred_entropy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy :  0.7733766233766234\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for reproducibility\n",
    "random_seed = 7\n",
    "\n",
    "# Define the number of trees to use in the random forest\n",
    "num_trees = 100\n",
    "\n",
    "# Define the maximum number of features to consider when splitting each tree\n",
    "max_features = 3\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "kfold_cv = KFold(n_splits=10)\n",
    "\n",
    "# Create a random forest classifier with the specified number of trees and maximum number of features\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features, random_state=random_seed)\n",
    "\n",
    "# Evaluate the random forest classifier using cross-validation\n",
    "scores = cross_val_score(model, X, Y, cv=kfold_cv)\n",
    "print(\"Random Forest Accuracy : \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Random Forest model on the training data\n",
    "trained_random_forest_model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[122  28]\n",
      " [ 33  48]]\n",
      "Accuracy: 73.59%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.81      0.80       150\n",
      "         1.0       0.63      0.59      0.61        81\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.71      0.70      0.71       231\n",
      "weighted avg       0.73      0.74      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the trained random forest model to make predictions on the test data\n",
    "y_pred_random_forest = trained_random_forest_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the random forest model predictions\n",
    "calculate_accuracy(y_test, y_pred_random_forest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.7720437457279563\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for reproducibility\n",
    "random_seed = 7\n",
    "\n",
    "# Define the base classifier\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Define the number of trees to use in the bagging classifier\n",
    "num_trees = 100\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "kfold_cv = KFold(n_splits=10)\n",
    "\n",
    "# Create a bagging classifier with the specified base classifier, number of trees, and random state\n",
    "model = BaggingClassifier(base_estimator=base_classifier, n_estimators=num_trees, random_state=random_seed)\n",
    "\n",
    "# Evaluate the bagging classifier using cross-validation\n",
    "scores = cross_val_score(model, X, Y, cv=kfold_cv)\n",
    "print(\"Bagging Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Bagging model on the training data\n",
    "trained_bagging_model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[123  27]\n",
      " [ 35  46]]\n",
      "Accuracy: 73.16%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.82      0.80       150\n",
      "         1.0       0.63      0.57      0.60        81\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.70      0.69      0.70       231\n",
      "weighted avg       0.73      0.73      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the trained Bagging model to make predictions on the test data\n",
    "y_pred_bagging = trained_bagging_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the Bagging model predictions\n",
    "calculate_accuracy(y_test, y_pred_bagging)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.760457963089542\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for reproducibility\n",
    "random_seed = 7\n",
    "\n",
    "# Define the number of trees to use in the AdaBoost classifier\n",
    "num_trees = 30\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "kfold_cv = KFold(n_splits=10)\n",
    "\n",
    "# Create an AdaBoost classifier with the specified number of trees and random state\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=random_seed)\n",
    "\n",
    "# Evaluate the AdaBoost classifier using cross-validation\n",
    "scores = cross_val_score(model, X, Y, cv=kfold_cv)\n",
    "print(\"AdaBoost Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the AdaBoost model on the training data\n",
    "trained_adaboost_model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[120  30]\n",
      " [ 37  44]]\n",
      "Accuracy: 71.00%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.80      0.78       150\n",
      "         1.0       0.59      0.54      0.57        81\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.68      0.67      0.67       231\n",
      "weighted avg       0.70      0.71      0.71       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the trained AdaBoost model to make predictions on the test data\n",
    "y_pred_adaboost = trained_adaboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the AdaBoost model predictions\n",
    "calculate_accuracy(y_test, y_pred_adaboost)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.7681989063568012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the seed for reproducibility\n",
    "random_seed = 7\n",
    "\n",
    "# Define the number of trees to use in the Gradient Boosting classifier\n",
    "num_trees = 100\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "kfold_cv = KFold(n_splits=10)\n",
    "\n",
    "# Create a Gradient Boosting classifier with the specified number of trees and random state\n",
    "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=random_seed)\n",
    "\n",
    "# Evaluate the Gradient Boosting classifier using cross-validation\n",
    "scores = cross_val_score(model, X, Y, cv=kfold_cv)\n",
    "print(\"Gradient Boosting Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Gradient Boosting model on the training data\n",
    "trained_gb_model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[117  33]\n",
      " [ 32  49]]\n",
      "Accuracy: 71.86%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.78      0.78       150\n",
      "         1.0       0.60      0.60      0.60        81\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.69      0.69      0.69       231\n",
      "weighted avg       0.72      0.72      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the trained Gradient Boosting model to make predictions on the test data\n",
    "y_pred_gb = trained_gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the Gradient Boosting model predictions\n",
    "calculate_accuracy(y_test, y_pred_gb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect on the applicability of the methods studied"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, various machine learning models were applied to the Pima Indians Diabetes Dataset to predict diabetes outcomes. The models used include linear regression, decision tree classifiers with gini and entropy, random forest, bagging, AdaBoost, and gradient boosting classifiers. The performance of each model was evaluated using cross-validation and different metrics such as accuracy and confusion matrix.\n",
    "\n",
    "The Random Forest model achieved the highest accuracy of 77.34%, compared to the others. The decision tree classifiers with gini and entropy, both resulted in an accuracy of 72.29% on the test set. Random Forest and Bagging achieved similar accuracies of 73.59% and 73.16% respectively, while AdaBoost and Gradient Boosting had accuracies of 71.00% and 71.86% respectively.\n",
    "\n",
    "Based on these results, the Random Forest model has the best performance for this dataset. However, it is also important to consider other metrics - especially in medical screening, a high recall is preferred to ensure that as many patients with the condition are identified. One type of error, in this case a false positive, is generally more preferable than the other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
